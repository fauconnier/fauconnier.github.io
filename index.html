<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <meta name="description" content="Jean-Philippe Fauconnier's Homepage">
        <meta name="keywords" content="Jean-Philippe Fauconnier, Computer Science,Natural Language Processing, Machine Learning, Artificial Intelligence">
        <meta name="author" content="Jean-Philippe Fauconnier">
        <meta http-equiv="X-UA-Compatible" content="chrome=1">
        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

        <title>Jean-Philippe Fauconnier</title>
        <link rel="stylesheet" href="stylesheets/styles.css">
        <link rel="stylesheet" href="stylesheets/pygment_trac.css">

        <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
      <![endif]-->

      <script src="//static.getclicky.com/js" type="text/javascript"></script>
      <script type="text/javascript">try{ clicky.init(100964614); }catch(e){}</script>
      <noscript><p><img alt="Clicky" width="1" height="1" src="//in.getclicky.com/100964614ns.gif" /></p></noscript>

      <!-- include some js files -->
      <script src="javascripts/css_browser_selector.js" type="text/javascript"></script>
      <script src="javascripts/scale.fix.js"></script>

    </head>
    <body>
        <div class="wrapper">

            <!-- Header -->
            <header>
                <h1>Jean-Philippe Fauconnier</h1>
                <p>I am Natural Language Processing and Machine Learning Researcher at Apple </p> <p>Previously, I have obtained my PhD in Computer Science at the Université Paul Sabatier (Toulouse, France) and I have completed my Master Degree in Natural Language Processing at the Catholic University of Louvain (Belgium).</p>
                <ul>
                    <li><a href="#about">About</a></li>
                    <li><a href="#research">Research</a></li>
                    <li><a href="#works">Works</a></li>
                    <li><a href="#teaching">Teaching</a></li>
                    <li><a href="#software">Software</a></li>
                    <li><a href="#data">Data</a></li>
                    <li><a href="#experience">Experience</a></li>
                    <!--<li><a href="#links">Links</a></li>-->
                </ul>
            </header>

            <!-- Content -->
            <section>
                <!-- About -->
                <h3 id="firsth">About<span id="about" class="anchor"/></h3>
                <p>I have obtained my PhD in Computer Science at the <a href="http://www.irit.fr" target="_blank">Toulouse Institute of Computer Science Research</a>, Université Paul Sabatier (France). My work took place under the supervision of Drs <a href="https://dblp.org/pers/hd/k/Kamel:Mouna" target="_blank">Mouna Kamel</a> and <a href="https://scholar.google.com/citations?user=qU7HrJAAAAAJ&hl=fr" target="_blank">Nathalie Aussenac-Gilles</a>, and focused on Natural Language Processing, Document Analysis and Machine Learning fields. More particularly, I was interested in the acquisition of lexical relations using the layout and the formatting of documents. For this work, I received the <a href="http://www.atala.org/prix-these" target="_blank">ATALA</a> <i>Best PhD Thesis Award</i>.</p>

				<p>Previously, I graduated in Natural Language Processing at the <a href="https://uclouvain.be/en/research" target="_blank">Catholic University of Louvain</a> (Belgium) in 2012. This Master's degree programme was delivered by the <a href="https://uclouvain.be/en/research-institutes/ilc/cental/presentation.html" target="_blank">CENTAL</a> laboratory.</p>

                <!-- Recent -->
                <h3>Recent (2024)<span id="recent" class="anchor"/></h3>
                <ul>
                    <li><strong>MM1</strong>: McKinzie, B., Gan, Z., Fauconnier, J., Dodge, S., Zhang, B., Dufter, P., Shah, D., Du, X., Peng, F., Weers, F. and Belyi, A., et. al., <a href="https://arxiv.org/abs/2403.09611" target="_blank">MM1: Methods, Analysis & insights from Multimodal LLM Pre-training.</a>, Milano, ECCV 2024</li>
                    <li><strong>RLHF</strong>: Amirloo, E., Fauconnier, J., Roesmann, C., Kerl, C., Boney, R., Qian, Y., Wang, Z., Dehghan, A., Yang, Y., Gan, Z. and Grasch, P. <a href="https://arxiv.org/abs/2407.02477"target="_blank">Understanding Alignment in Multimodal LLMs: A Comprehensive Study.</a>, 2024.</li>
                    <li><strong>Instruction-Following</strong>: Qian, Y., Ye, H., Fauconnier, J., Grasch, P., Yang, Y. and Gan, Z. <a href="https://arxiv.org/abs/2407.01509" target="_blank">MIA-Bench: Towards Better Instruction Following Evaluation of Multimodal LLMs.</a> 2024.</li>
                </ul>



                <!-- Research interests -->
                <h3>Research Interests<span id="research" class="anchor"/></h3>

                <h4>Natural Language Processing</h4>
                <ul>
                    <li><strong>Analysis</strong>: morpho-lexical analysis and syntactic parsing</li>
                    <li><strong>Corpora</strong>: development of annotation tools, annotation campaigns, and inter-rater agreement evaluation</li>
                    <li><strong>Meaning</strong>: ontology learning from text and Word embeddings</li>
                </ul>
                <h4>Document Analysis</h4>
                <ul>
                    <li><strong>Logical modeling</strong>: links between physical layout structures and logical ones</li>
                    <li><strong>LR Parsing</strong>: statistical and context-free grammar parsing for building logical tree</li>
                </ul>
                <h4>Statistics</h4>
                <ul>
                    <li><strong>Predictive modeling</strong>: supervised classification, structured prediction and unsupervised feature selection</li>
                    <li><strong>Descriptive analytics</strong>: statistical relationships and multivariate analysis </li>
                </ul>


                <!-- Works -->
                <h3>Works<span id="works" class="anchor"/></h3>

                <h4>National journal papers</h4>
                <ul>
                    <li>M. Kamel, B. Rothenburger, J.-P. Fauconnier. <i>Identification de relations sémantiques portées par les structures énumératives paradigmatiques : une approche symbolique et une approche par apprentissage supervisé</i>. Revue d'Intelligence Artificielle, Hermès Science, Numéro spécial Ingénierie des Connaissances. Nouvelles évolutions., Vol. 28, N. 2-3, p. 271-296, 2014. </li>
                </ul>
                <h4>International conference papers</h4>
                <ul>
                    <li>J.-P. Fauconnier, M. Kamel. <i>Discovering Hypernymy Relations using Text Layout</i> (regular paper). The Fourth Joint Conference on Lexical and Computational Semantics (*SEM 2015), Denver, Colorado, 2015. <a href="https://embeddings.net/papers/Fauconnier_Kamel_SEM2015.pdf">PDF</a> </li>
                    <li>J.-P. Fauconnier, M. Kamel, B. Rothenburger. <i>A Supervised Machine Learning Approach for Taxonomic Relation Recognition through Non-linear Enumerative Structures</i> (short paper). ACM Symposium on Applied Computing (SAC 2015), Salamanque, 2015. <a href="https://embeddings.net/papers/Fauconnier_et_al_SWA2015.pdf">PDF</a> </li>
                    <li> J.-P. Fauconnier, M. Kamel, B. Rothenburger. <i>Une typologie multi-dimensionnelle des structures énumératives pour l'identification des relations termino-ontologiques</i> (regular paper). Conférence Internationale sur la Terminologie et l'Intelligence Artificielle (TIA 2013), Paris, Université Paris 13, p. 137-144, 2013. <a href="https://embeddings.net/papers/Fauconnier_et_al_TIA2013.pdf">PDF</a></li>
                </ul>

                <h4>National conference papers</h4>
                <ul>
                    <li>J.-P. Fauconnier, L. Sorin, M. Kamel, Mustapha Mojahid, N. Aussenac-Gilles. <i>Détection automatique de la structure organisationnelle de documents à partir de marqueurs visuels et lexicaux</i> (regular paper). Traitement Automatique des Langues Naturelles (TALN 2014), Marseille, Association pour le Traitement Automatique des Langues (ATALA), p. 340-351, 2014. <a href="https://embeddings.net/papers/Fauconnier_et_al_TALN2014.pdf">PDF</a> </li>
                    <li>J.-P. Fauconnier, M. Kamel, B. Rothenburger, N. Aussenac-Gilles. <i>Apprentissage supervisé pour l'identification de relations sémantiques au sein de structures énumératives parallèles</i> (regular paper). Traitement Automatique des Langues Naturelles (TALN 2013), Les Sables d'Olonne, Association pour le Traitement Automatique des Langues (ATALA), p. 132-145, 2013. <a href="https://embeddings.net/papers/Fauconnier_et_al_TALN2013.pdf">PDF</a></li>
                </ul>

                <h4>Phd Thesis</h4>
                <ul>
                    <li>J.-P. Fauconnier, <i>Acquisition de liens sémantiques à partir d'éléments de mise en forme des textes : exploitation des structures énumératives</i> (PhD Thesis). Université de Toulouse, 2016. <a href="https://tel.archives-ouvertes.fr/tel-01324765/file/Fauconnier_2016.pdf">PDF</a> <a href="https://tel.archives-ouvertes.fr/tel-01324765">HAL</a> (Best PhD Thesis Award - ATALA 2017)</li>
                </ul>

                <h4>Talks</h4>
                <ul>
                    <li>J.-P. Fauconnier. <i>La mise en forme des textes : un indice supplémentaire pour l'identification des relations hiérarchiques</i> (talk). Séminaire de l'équipe TALEP, Laboratoire d'Informatique Fondamentale de Marseille, 20-05-16.</li>
                    <li>J.-P. Fauconnier. <i>Mise en forme et indices linguistiques de surface pour l'extraction de connaissances</i> (talk). Journées d'étude internationales S'caladis, Université Toulouse Jean Jaurès, Toulouse, 19-11-15. <a href="http://w3.erss.univ-tlse2.fr/JE_Enumeration2015/Resumes/Fauconnier_JEenumeration2015.pdf">Abstract</a></li>
                    <li>J.-P. Fauconnier, M. Kamel, N. Aussenac-Gilles. <i>Acquisition de relations sémantiques à partir d’éléments de mise en forme des textes</i> (talk). Séminaires du CENTAL, Université Catholique de Louvain, Louvain-la-Neuve, 21-11-14. <a href="https://embeddings.net/papers/Fauconnier_2014_CENTAL.pdf">PDF</a></li>
                    <li>J.-P. Fauconnier. <i>Métriques pour l’évaluation de l’annotation</i> (talk). Séminaires de l’équipe MELODI, Université Paul Sabatier, Toulouse, 25-11-13. <a href="http://www.slideshare.net/jfaucon/mtriques-pour-lvaluation-de-lannotation" target="_blank">Link</a></li>
                    <li>J.-P. Fauconnier, M. Kamel, N. Aussenac-Gilles. <i>A Supervised Learning for the Identification of Semantic Relations in Parallel Enumerative Structures</i> (poster). The 10th Summer School on Ontology Engineering and the Semantic Web (SSSW 2013), Cercédilla, 10-07-13. <a href="https://embeddings.net/papers/Fauconnier_SSSW2013.pdf">PDF</a></li>
                    <li>J.-P. Fauconnier. <i>Classifieur d’Entropie Maximale (MaxEnt)</i> (talk). Séminaires de l’équipe MELODI, Université Paul Sabatier, Toulouse, 15-02-13. <a href="http://www.slideshare.net/jfaucon/max-ent" target="_blank">Link</a></li>
                    <li>A. Urieli, J.-P. Fauconnier. <i>PosTagger et Parseur Talismane</i> (talk). Séminaires de l’Axe TAL, CLLE-ERSS, Toulouse, 20-06-12. <a href="https://embeddings.net/papers/Urieli_Fauconnier_2012.pdf">PDF</a></li>
                    <li>J.-P. Fauconnier, J. Roumier, F. Estiévenart. <i>Musonto - A Semantic Search Engine dedicated to Music and Musicians</i> (talk). Music Linked Data Workshop, JISC, Londres, 12-05-11. <a href="http://www.slideshare.net/MusicNet/jp-fauconnier-j-roumier-musonto-a-semantic-search-engine-dedicated-to-music-and-musicians" target="_blank">Link</a></li>
                </ul>


                <!-- Teaching -->
                <h3>Teaching<span id="teaching" class="anchor"/></h3>
                <h4>2015-2016</h4>
                <ul>
                    <li>Algorithms and C++ Programming - 54 hours - Université Jean Jaurès (Toulouse, France)</li>
                    <li>Relational Database - 44 hours - Université Jean Jaurès (Toulouse, France)</li>
                    <li>Web Integration - 40 hours - Université Jean Jaurès (Toulouse, France) </li>
                    <li>C2I Certification - 36 hours - Université Jean Jaurès (Toulouse, France) </li>
                    <li>XML technologies - 12 hours - Université Jean Jaurès (Toulouse, France)</li>
                    <li>Semantic Web - 4 hours - Université Jean Jaurès (Toulouse, France)</li>
                </ul>

                <h4>2014-2015</h4>
                <ul>
                    <li>Web Integration - 24 hours - Institut Universitaire de Technologie (Tarbes, France)</li>
                    <li>Relational Database - 18 hours - Institut Universitaire de Technologie (Tarbes, France)</li>
                    <li>Web Integration - 18 hours - Institut Universitaire de Technologie (Tarbes, France)</li>
                </ul>

                <h4>2013-2014</h4>
                <ul>
                    <li>Web Integration - 36 hours - Institut Universitaire de Technologie (Tarbes, France)</li>
                    <li>Relational Database - 12 hours - Institut Universitaire de Technologie (Tarbes, France)</li>
                    <li>Information System - 12 hours - Institut Universitaire de Technologie (Tarbes, France)</li>
                </ul>

                <h4>2012-2013</h4>
                <ul>
                    <li>Office Automation - 40 hours - Institut Universitaire de Technologie (Tarbes, France)</li>
                    <li>Office Automation - 24 hours - Institut Universitaire de Technologie (Tarbes, France)</li>
                </ul>

                <!-- Software -->
                <h3>Software<span id="software" class="anchor"/></h3>
                <p>Most of resources are located on my <a href="https://github.com/fauconnier?tab=repositories" class="user-mention" target="_blank">github repository</a>. The fast way to download a given <i>resource</i> is to use git:</p>
                <pre><code>mkdir resource
cd resource
git clone https://github.com/fauconnier/resource</code></pre>

                <h4>Personal softwares</h4>
                <a href="https://github.com/fauconnier/AMI" target="_blank"><img src="./pics/ami.png" alt="AMI" class="projectpic"/></a>
                <p><a href="https://github.com/fauconnier/AMI" target="_blank">AMI</a> (<i>Another Maxent Implementation</i>) is a R implementation of multinomial logistic regression, also known as Maximum Entropy classifier. This implementation deals with binary and real-valued features and uses standard R functions to optimize the objective. Then, it is possible to use several iterative methods: LM-BFGS, Conjugate Gradient, Gradient Descent and Generalized Iterative Scaling.</p>

                <a href="https://github.com/fauconnier/LARAt" target="_blank"><img src="./pics/larat.png" alt="LARAt" class="projectpic"/></a>
                <p><a href="https://github.com/fauconnier/LARAt" target="_blank">LARAt</a> (<i>Layout Annotation for Relation Acquisition tool</i>), pronounced /laʁa/, is an annotation tool which supports the layout and the formatting of HTML documents. LARAt was used during an annotation campaign in 2013 and, in his current state, is dedicated to the annotation of enumerative structures. The typology implemented is the one described in the TIA 2013 paper.</p>

                <a href="https://github.com/fauconnier/LaToe" target="_blank"><img src="./pics/latoe.png" alt="LaToe" class="projectpic"/></a>
                <p><a href="https://github.com/fauconnier/LaToe" target="_blank">LaToe</a> (<i>Layout Annotation for Textual Object Extraction</i>) is a tool which extracts the text layout from HTML, MediaWiki, or PDF documents for identifying specific textual objects (such as enumerative structures). Currently, the CRF model used for the PDF analyzer was trained on a small corpus (LING_GEOP). This implies that LaToe could be not efficient for unseen PDF documents with specific formatting. </p>


                <h4>Source code reviews</h4>
                <a href="https://github.com/fauconnier/code_review_tsuruoka" target="_blank"><img src="./pics/code_review_tsuruoka.png" alt="code_review_tsuruoka" class="projectpic"/></a>
                <p><a href="https://github.com/fauconnier/code_review_tsuruoka" target="_blank">Code review</a> of a <i>C++ library for maximum entropy classification</i>. On his website, <a href="http://www.logos.ic.i.u-tokyo.ac.jp/~tsuruoka/" target="_blank">Tsuruoka</a> proposed a <a href="http://www.logos.ic.i.u-tokyo.ac.jp/~tsuruoka/maxent/" target="_blank">fast implementation</a> of a multinomial logistic regression. In order to get a better and deeper understanding of implementation details, I propose a simple code review. The code base is relatively small (around 2500 lines of code). Those notes are primary intended for my personal use and reflect my current understanding. I propose them here, in case it could help someone. Note that this document is currently a work in progress.</p>

                <h4>Open source contributions</h4>
                Some open source contributions:
                <ul>

                    <li><strong>2016</strong>
                    <ul>

                        <li><a href="https://github.com/kassio/neoterm" target="_blank">neoterm</a> (<i>vim module</i>) Fixed documentation. <a href="https://github.com/kassio/neoterm/pull/82" target="_blank">PR</a></li>

                        <li><a href="https://github.com/dkastner/sc" target="_blank">sc</a> (<i>spreadsheet calculator</i>) Updated sc 7.16. <a href="https://github.com/dkastner/sc/commit/d3ddd9687228f240fb3f66e0b7e4d4ccf5df012e" target="_blank">commit</a></li>

                        <li><a href="https://github.com/dkastner/sc" target="_blank">sc</a> (<i>spreadsheet calculator</i>) Fixed conflicting malloc. <a href="https://github.com/dkastner/sc/pull/1" target="_blank">PR</a></li>
                    </ul>
                    </li>

                    <li><strong>2015</strong>
                    <ul>
                        <li><a href="https://code.google.com/archive/p/lapdftext/" target="_blank">LAPDFText</a> (<i>Layout-Aware PDF Analyser</i>) Led a student for improving bottom-up parsing and building a GUI. <a href="https://github.com/fauconnier/lapdftext" target="_blank">fork</a></li>
                    </ul>
                    </li>



                    <li><strong>2014</strong>
                    <ul>
                        <li><a href="https://java.net/projects/frej" target="_blank">FREJ</a> (<i>Fuzzy Regular Expressions</i>) Client-server architecture for spreading the load across a cluster. <a href="https://github.com/fauconnier/fuzzymatcher-server" target="_blank">github</a></li>

                        <li><a href="http://search.cpan.org/%7Ethhamon/Lingua-YaTeA/" target="_blank">YaTeA</a> (<i>terminology extractor</i>) Adaptation to Talismane POS-tagset and Java client. <a href="https://github.com/fauconnier/yatea-client" target="_blank">github</a></li>

                        <li><a href="http://www.bdaille.com/index.php?option=com_content&task=blogcategory&id=5&Itemid=5&lang=en" target="_blank">ACABIT</a> (<i>terminology extractor</i>) Adaptation to Talismane POS-tagset and Java client. <a href="https://github.com/fauconnier/acabit-client" target="_blank">github</a> </li>

                        <li><a href="https://github.com/urieli/talismane" target="_blank">Talismane</a> (<i>statistical dependency parser for French</i>) Java client for treating corpora "on-the-fly".  <a href="https://github.com/fauconnier/talismane-client" target="_blank">github</a></li>
                    </ul>
                    </li>

                    <li><strong>2013-12</strong>
                    <ul>
                        <li><a href="https://github.com/urieli/talismane" target="_blank">Talismane</a> (<i>statistical dependency parser for French</i>) Minor fix.  <a href="https://github.com/urieli/talismane/commit/ec873be19b44367578320b5c5c3a03a207cc3eb4" target="_blank">commit</a></li>

                        <li><a href="https://github.com/urieli/talismane" target="_blank">Talismane</a> (<i>statistical dependency parser for French</i>) First version of user's manual. <a href="http://urieli.github.io/talismane/" target="_blank">last version</a></li>
                    </ul>
                    </li>

                </ul>

                <!-- Data -->
                <h3>Data<span id="data" class="anchor"/></h3>

                <h4>French word embeddings models<span id="wordembeddingmodels" class="anchor"/></h4>
                <p>I propose here some pre-trained word2vec models for French. Their format is the original binary format proposed by <a href="http://code.google.com/p/word2vec/" target="_blank">word2vec v0.1c</a>. Depending on your needs, you may want to convert those models. A simple way to convert them into text can be: </p>
                <pre><code>git clone https://github.com/marekrei/convertvec
cd convertvec/
make
./convertvec bin2txt frWiki_no_phrase_no_postag_700_cbow_cut100.bin output.txt
</code></pre>
                <p>Alternatively, you can load a binary model directly into a few Python libraries. Below I give a minimal usage example with Gensim:</p>

                <pre><code>pip install gensim
python
>>> from gensim.models import KeyedVectors
>>> model = KeyedVectors.load_word2vec_format(<span style="color:purple">"frWac_postag_no_phrase_700_skip_cut50.bin"</span>, binary=True, unicode_errors="ignore")
>>> model.most_similar(<span style="color:red">"intéressant_a"</span>)
[(<span style="color:blue">'très_adv'</span>        , 0.5967904925346375),
(<span style="color:green">'intéresser_v'</span>     , 0.5439727902412415),
(<span style="color:blue">'peu_adv'</span>          , 0.5426771640777588),
(<span style="color:blue">'assez_adv'</span>        , 0.5398581027984619),
(<span style="color:blue">'certainement_adv'</span> , 0.5246292352676392),
(<span style="color:blue">'plutôt_adv'</span>       , 0.5234975814819336),
(<span style="color:red">'instructif_a'</span>     , 0.5230029225349426),
(<span style="color:green">'trouver_v'</span>        , 0.5131329894065857),
(<span style="color:blue">'aussi_adv'</span>        , 0.505642294883728),
(<span style="color:blue">'beaucoup_adv'</span>     , 0.5034803152084351)]
</code></pre>

<p>For this model, we can see that the adjective 'intéressant' has a lot of shared contexts with adverbs.  Note that the color code and the layout are mine.
Please check (<a href="https://arxiv.org/abs/1310.4546" target="_blank">Mikolov et al., 2013</a>) to gain insight into the model hyper-parameters.</p>

<p>Thanks to Tim V. C., Adam B., Claude C., Sascha R., Philipp D., Nirina R., Ian W. and Antoine V. who all helped in retrieving some of the original models.</p>

                <h5>frWac2Vec</h5>
                <p><a href="http://wacky.sslmit.unibo.it/doku.php?id=corpora" target="_blank">FrWac corpus</a>, 1.6 billion words. </p>
                <table>
                    <tr>
                        <td></td>
                        <td>lem</td>
                        <td>pos</td>
                        <td>phrase</td>
                        <td>train</td>
                        <td>dim</td>
                        <td>cutoff</td>
                        <td>md5</td>
                    </tr>
                    <tr>
                        <td><a href="https://embeddings.net/embeddings/frWac_non_lem_no_postag_no_phrase_200_cbow_cut0.bin">bin (2.7Gb)</a></td>
                        <td>-</td>
                        <td>-</td>
                        <td>-</td>
                        <td>cbow</td>
                        <td>200</td>
                        <td>0</td>
                        <td><a href="https://embeddings.net/embeddings/md5sum.txt">7e49</td>
                    </tr>
                    <tr>
                        <td><a href="https://embeddings.net/embeddings/frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin">bin (120Mb)</a></td>
                        <td>-</td>
                        <td>-</td>
                        <td>-</td>
                        <td>cbow</td>
                        <td>200</td>
                        <td>100</td>
                        <td><a href="https://embeddings.net/embeddings/md5sum.txt">5b5f</td>
                    </tr>
                    <tr>
                        <td><a href="https://embeddings.net/embeddings/frWac_non_lem_no_postag_no_phrase_200_skip_cut100.bin">bin (120Mb)</a></td>
                        <td>-</td>
                        <td>-</td>
                        <td>-</td>
                        <td>skip</td>
                        <td>200</td>
                        <td>100</td>
                        <td><a href="https://embeddings.net/embeddings/md5sum.txt">6b86</td>
                    </tr>
                    <tr>
                        <td><a href="https://embeddings.net/embeddings/frWac_non_lem_no_postag_no_phrase_500_skip_cut100.bin">bin (298Mb)</a></td>
                        <td>-</td>
                        <td>-</td>
                        <td>-</td>
                        <td>skip</td>
                        <td>500</td>
                        <td>100</td>
                        <td><a href="https://embeddings.net/embeddings/md5sum.txt">af38</td>
                    </tr>
                    <tr>
                        <td><a href="https://embeddings.net/embeddings/frWac_non_lem_no_postag_no_phrase_500_skip_cut200.bin">bin (202Mb)</a></td>
                        <td>-</td>
                        <td>-</td>
                        <td>-</td>
                        <td>skip</td>
                        <td>500</td>
                        <td>200</td>
                        <td><a href="https://embeddings.net/embeddings/md5sum.txt">e2c6</td>
                    </tr>
                    <tr>
                        <td><a href="https://embeddings.net/embeddings/frWac_no_postag_no_phrase_500_cbow_cut100.bin">bin (229Mb)</a></td>
                        <td>&or;</td>
                        <td>-</td>
                        <td>-</td>
                        <td>cbow</td>
                        <td>500</td>
                        <td>100</td>
                        <td><a href="https://embeddings.net/embeddings/md5sum.txt">1c85</td>
                    </tr>
                    <tr>
                        <td><a href="https://embeddings.net/embeddings/frWac_no_postag_no_phrase_500_skip_cut100.bin">bin (229Mb)</a></td>
                        <td>&or;</td>
                        <td>-</td>
                        <td>-</td>
                        <td>skip</td>
                        <td>500</td>
                        <td>100</td>
                        <td><a href="https://embeddings.net/embeddings/md5sum.txt">54fc</td>
                    </tr>
                    <tr>
                        <td><a href="https://embeddings.net/embeddings/frWac_no_postag_no_phrase_700_skip_cut50.bin">bin (494Mb)</a></td>
                        <td>&or;</td>
                        <td>-</td>
                        <td>-</td>
                        <td>skip</td>
                        <td>700</td>
                        <td>50</td>
                        <td><a href="https://embeddings.net/embeddings/md5sum.txt">e235</td>
                    </tr>
                    <tr>
                        <td><a href="https://embeddings.net/embeddings/frWac_postag_no_phrase_700_skip_cut50.bin">bin (577Mb)</a></td>
                        <td>&or;</td>
                        <td>&or;</td>
                        <td>-</td>
                        <td>skip</td>
                        <td>700</td>
                        <td>50</td>
                        <td><a href="https://embeddings.net/embeddings/md5sum.txt">0695</td>
                    </tr>
                    <tr>
                        <td><a href="https://embeddings.net/embeddings/frWac_postag_no_phrase_1000_skip_cut100.bin">bin (520Mb)</a></td>
                        <td>&or;</td>
                        <td>&or;</td>
                        <td>-</td>
                        <td>skip</td>
                        <td>1000</td>
                        <td>100</td>
                        <td><a href="https://embeddings.net/embeddings/md5sum.txt">8d09</td>
                    </tr>
                    <tr>
                        <td><a href="https://embeddings.net/embeddings/frWac_no_postag_phrase_500_cbow_cut10.bin">bin (2Gb)</a></td>
                        <td>&or;</td>
                        <td>-</td>
                        <td>&or;</td>
                        <td>cbow</td>
                        <td>500</td>
                        <td>10</td>
                        <td><a href="https://embeddings.net/embeddings/md5sum.txt">14da</td>
                    </tr>
                    <tr>
                        <td><a href="https://embeddings.net/embeddings/frWac_no_postag_phrase_500_cbow_cut100.bin">bin (289Mb)</a></td>
                        <td>&or;</td>
                        <td>-</td>
                        <td>&or;</td>
                        <td>cbow</td>
                        <td>500</td>
                        <td>100</td>
                        <td><a href="https://embeddings.net/embeddings/md5sum.txt">f500</td>
                    </tr>
                </table>

                <h5>frWiki2Vec</h5>
                <p><a href="https://dumps.wikimedia.org/frwiki/" target="_blank">FrWiki dump</a>  (<a href="https://embeddings.net/embeddings/frWiki_non_lem.txt.gz">raw file</a>), 600 millions words.</p>
                <table>
                    <tr>
                        <td></td>
                        <td>lem</td>
                        <td>pos</td>
                        <td>phrase</td>
                        <td>train</td>
                        <td>dim</td>
                        <td>cutoff</td>
                        <td>md5</td>
                    </tr>
                    <tr>
                        <td><a href="https://embeddings.net/embeddings/frWiki_no_lem_no_postag_no_phrase_1000_cbow_cut100.bin">bin (253Mb)</a></td>
                        <td>-</td>
                        <td>-</td>
                        <td>-</td>
                        <td>cbow</td>
                        <td>1000</td>
                        <td>100</td>
                        <td><a href="https://embeddings.net/embeddings/md5sum.txt">087c</td>
                    </tr>
                    <tr>
                        <td><a href="https://embeddings.net/embeddings/frWiki_no_lem_no_postag_no_phrase_1000_cbow_cut200.bin">bin (195Mb)</a></td>
                        <td>-</td>
                        <td>-</td>
                        <td>-</td>
                        <td>cbow</td>
                        <td>1000</td>
                        <td>200</td>
                        <td><a href="https://embeddings.net/embeddings/md5sum.txt">0a19</td>
                    </tr>
                    <tr>
                        <td><a href="https://embeddings.net/embeddings/frWiki_no_lem_no_postag_no_phrase_1000_skip_cut100.bin">bin (253Mb)</a></td>
                        <td>-</td>
                        <td>-</td>
                        <td>-</td>
                        <td>skip</td>
                        <td>1000</td>
                        <td>100</td>
                        <td><a href="https://embeddings.net/embeddings/md5sum.txt">7d5c</td>
                    </tr>
                    <tr>
                        <td><a href="https://embeddings.net/embeddings/frWiki_no_lem_no_postag_no_phrase_1000_skip_cut200.bin">bin (195Mb)</a></td>
                        <td>-</td>
                        <td>-</td>
                        <td>-</td>
                        <td>skip</td>
                        <td>1000</td>
                        <td>200</td>
                        <td><a href="https://embeddings.net/embeddings/md5sum.txt">48a0</td>
                    </tr>
                    <tr>
                        <td><a href="https://embeddings.net/embeddings/frWiki_no_phrase_no_postag_500_cbow_cut10.bin">bin (128Mb)</a></td>
                        <td>&or;</td>
                        <td>-</td>
                        <td>-</td>
                        <td>cbow</td>
                        <td>500</td>
                        <td>10</td>
                        <td><a href="https://embeddings.net/embeddings/md5sum.txt">052f</td>
                    </tr>
                    <tr>
                        <td><a href="https://embeddings.net/embeddings/frWiki_no_phrase_no_postag_700_cbow_cut100.bin">bin (106Mb)</a></td>
                        <td>&or;</td>
                        <td>-</td>
                        <td>-</td>
                        <td>cbow</td>
                        <td>700</td>
                        <td>100</td>
                        <td><a href="https://embeddings.net/embeddings/md5sum.txt">8ff0</td>
                    </tr>
                    <tr>
                        <td><a href="https://embeddings.net/embeddings/frWiki_no_phrase_no_postag_1000_skip_cut100.bin">bin (151Mb)</a></td>
                        <td>&or;</td>
                        <td>-</td>
                        <td>-</td>
                        <td>skip</td>
                        <td>1000</td>
                        <td>100</td>
                        <td><a href="https://embeddings.net/embeddings/md5sum.txt">5ac9</td>
                    </tr>
                    <tr>
                        <td><a href="https://embeddings.net/embeddings/frWiki_no_phrase_no_postag_1000_skip_cut200.bin">bin (121Mb)</a></td>
                        <td>&or;</td>
                        <td>-</td>
                        <td>-</td>
                        <td>skip</td>
                        <td>1000</td>
                        <td>200</td>
                        <td><a href="https://embeddings.net/embeddings/md5sum.txt">bc16</td>
                    </tr>
                </table>

                </br>
                <h5>How to cite those models?</h5>
                <p>Given the attribution is provided and according to the licence  <a href="https://creativecommons.org/licenses/by/3.0/legalcode" target="_blank">CC-BY 3.0</a>, you are free to copy, distribute, remix and tweak those models for any purpose. The attribution must be made by quoting my name with a link to <a href="http://fauconnier.github.io">this page</a>, or by using the bibtex entry below. Those models were trained during my PhD Thesis, and are in no way linked to my current or any future activities. Note also that those models are shared without any guarantees or support.</p>

<code><pre>
@misc{fauconnier_2015,
	author = {Fauconnier, Jean-Philippe},
	title = {French Word Embeddings},
	url = {http://fauconnier.github.io},
	year = {2015}}
</code></pre>
                <p>Below, public projects and papers using those models:</p>
                <ul>
            <li> Di Tella et al., (2023), <i>Keep your Enemies Closer: Strategic Platform Adjustments during U.S. and French Elections</i>. in National Bureau of Economic Research (NBER), NBER Working Paper Series. <a href="https://www.nber.org/system/files/working_papers/w31503/revisions/w31503.rev0.pdf" target="_blank">PDF</a></li>
            <li> Rennard, V., Shang, G., Grari, D., Hunter, J. and Vazirgiannis, M. (2023), <i>FREDSum: A Dialogue Summarization Corpus for French Political Debates</i>. in EMNLP 2023. <a href="https://aclanthology.org/2023.findings-emnlp.280.pdf" target="_blank">PDF</a></li>
            <li>Ivan, I., and Chometton, N. (2022).  <i>Alignement des embeddings des définitions et du contexte pour un assistant de lecture sensible au contexte</i>. In Journées Jointes des Groupements de Recherche Linguistique Informatique, Formelle et de Terrain (LIFT) et Traitement Automatique des Langues (TAL). <a href="https://hal.science/hal-03846828/document" target="_blank">PDF</a></li>
            <li>Descampe, A., Massart, C., Poelman, S., Standaert, F. X., and Standaert, O. (2022).  <i>Automated news recommendation in front of adversarial examples and the technical limits of transparency in algorithmic accountability.</i>. In  AI and SOCIETY. Université Catholique de Louvain. <a href="https://perso.uclouvain.be/fstandae/PUBLIS/259.pdf" target="_blank">PDF</a></li>
            <li>Eshkol-Taravella, I., Barbedette, A., Liu, X., Soumah, V.-G. (2022) <i>Classification automatique de questions spontanées vs. préparées dans des transcriptions de l’oral</i>. In TALN 2022. <a href="https://aclanthology.org/2022.jeptalnrecital-taln.30.pdf" target="_blank">PDF</a></li>
            <li>bpisano (2022). <i>Dall-E Guesser</i>. &mdash; <a href="https://dalle-guesser.herokuapp.com" target="_blank">Application</a></li>
            <li>Guillem, F. (2022). <i>Analyse des Programmes de la Présidentielle 2022 avec Word2vec</i>. Le Blog de François Guillem. <a href="https://francoisguillem.fr/2022/04/analyse-des-programmes-de-la-presidentielle-2022-avec-word2vec/" target="_blank">Blog</a></li>
            <li>Benamar, A, Grouin, C., Bothua, M. and Vilnat, A. (2022). <i>Etude des stéréotypes genrés dans le théâtre français du XVIe au XIXe siècle à travers des plongements lexicaux</i>. In TALN 2022. <a href="https://aclanthology.org/2022.jeptalnrecital-taln.7.pdf" target="_blank">PDF</a></li>
            <li>Enigmatix (2022). <i>Cémantix</i>. Trouvez le mot secret &mdash; <a href="https://cemantix.certitudes.org" target="_blank">Application</a></li>
            <li>Tardy, P. (2021). <i>Approches neuronales pour le résumé abstractif de transcriptions de parole</i>. PhD Thesis Le Mans Université. <a href="https://tel.archives-ouvertes.fr/tel-03259468/document" target="_blank">PDF</a></li>
            <li>Schoffeniels, A. (2021). <i>NLP Methods for Insurance Document Comparison</i>. Master Thesis University of Liège. <a href="https://matheo.uliege.be/bitstream/2268.2/13271/1/Schoffeniels2020.pdf" target="_blank">PDF</a></li>
            <li>Mallart, C., Le Nouy, M., Gravier, G., and Sébillot, P. (2021). <i>Active Learning for Interactive Relation Extraction in a French Newspaper's Articles</i>. Recent Advances in Natural Language Processing. <a href="https://hal.archives-ouvertes.fr/hal-03371917/file/ranlp2021.pdf" target="_blank">PDF</a></li>
            <li>Barbedette, A., and Eshkol-Taravella, I. (2021). <i>Quand les questions en disent plus que les réponses: classification automatique des intentions dans les questions</i>. Discours (28). <a href="https://doi.org/10.4000/discours.11359" target="_blank">OpenEdition</a></li>
            <li>Wang, X and Liu, X. (2021). <i>Text Classification: du TF-IDF aux word embeddings en passant par features expertes</i>. NLP for French. <a href="https://nlpforfrench.fr/nlp/03_classification_lemonde_fr.html" target="_blank">Blog</a></li>
            <li>Abdine, H., Xypolopoulos, C., Kamal Eddine, M. and Vazirgiannis, M. (2021). <i>Evaluation of Word Embeddings from Large-Scale French Web Content</i>. arXiv:2105.01990v2. <a href="https://arxiv.org/pdf/2105.01990.pdf" target="_blank">arXiv</a></li>
            <li>Louis, A., Spanakis, G., and Van Dijck, G. (2021). <i>A Statutory Article Retrieval Dataset in French</i>. arXiv preprint arXiv:2108.11792. <a href="https://arxiv.org/abs/2108.11792" target="_blank">arXiv</a></li>
            <li>Gerardin, M. and Ranvier, M. (2021). <i>Enrichment of the Banque de France’s monthly business survey: lessons from textual analysis of business leaders’ comments</i>. Working Paper &mdash; Banque de France. <a href="https://publications.banque-france.fr/sites/default/files/medias/documents/wp821.pdf" target="_blank">PDF</a></li>
            <li>Crouzet, O. (2021). <i>Outils computationnels pour l'étude des mécanismes d'adaptation à la variation en perception de la parole</i>. La lettre de I’InSHS &mdash; CNRS. <a href="https://www.inshs.cnrs.fr/sites/institut_inshs/files/download-file/lettre_infoINSHS_69.pdf" target="_blank">PDF</a></li>
            <li>Dénigot, Q. and Burnett, H. (2021). <i>Using Word Embeddings to Uncover Discourses</i>. In Proceedings of Computation in Linguistics. <a href="https://scholarworks.umass.edu/cgi/viewcontent.cgi?article=1190&context=scil" target="_blank">PDF</a></li>
            <li>Lambrey, L. (2021). <i>Génération automatique de mots-valises : approche distributionnelle de la classification sémantique de construits</i>. In Journée d'Étude Sciences du Langage, Nancy. <a href="https://lginterface.sciencesconf.org/data/program/Lambrey_mots_valises.pdf" target="_blank">PDF</a></li>
            <li>Billami, M. B., Nicolaieff, L., Gosset, C. and Bortolaso, C. (2021). <i>Participation de Berger-Levrault (BL. Research) à DEFT 2021: de l’apprentissage des seuils de validation à la classification multi-labels de documents</i>. In TALN 2021. <a href="https://hal.archives-ouvertes.fr/hal-03265918/document" target="_blank">PDF</a></li>
            <li>Hemamou, L. (2021). <i>Analyse automatique des comportements multimodaux lors d’entretiens vidéo différés pour le recrutement</i>. PhD Thesis Université Paris-Saclay. <a href="https://tel.archives-ouvertes.fr/tel-03244726/document" target="_blank">PDF</a></li>
            <li>Le, N. L. (2020). <i>French Language DRS Parsing</i>. PhD Thesis Mines-Telecom Atlantique. <a href="https://tel.archives-ouvertes.fr/tel-03132658/document" target="_blank">PDF</a></li>
            <li>Tardy, P., Janiszek, D., Estève, Y., and Nguyen, V. (2020). <i>Align then Summarize: Automatic Alignment Methods for Summarization Corpus Creation</i>. In Proceedings of LREC 2020. <a href="https://www.aclweb.org/anthology/2020.lrec-1.829.pdf" target="_blank">PDF</a></li>
            <li>Blandin, A., Lecorvé, G., Battistelli, D., and Étienne, A. (2020). <i>Age Recommendation for Texts</i>. In Proceedings of LREC 2020. <a href="https://www.aclweb.org/anthology/2020.lrec-1.179.pdf" target="_blank">PDF</a></li>
            <li>Kang, H. J. and Eshkol-Taravella, I. (2020). <i>Les avis sur les restaurants à l’épreuve de l’apprentissage automatique</i>. In TALN 2020.  <a href="https://www.aclweb.org/anthology/2020.lrec-1.829.pdf" target="_blank">PDF</a></li>
            <li>Leprieur, L., Crouzet, O., and Gaudrain, E. (2020). <i>Une base de données de phrases en français pour l'étude du rôle conjoint des incertitudes sémantique et acoustique dans la perception de la parole</i>. In TALN 2020. <a href="https://hal-ujm.archives-ouvertes.fr/hal-02798558/" target="_blank">PDF</a></li>
            <li>Benamar, A. (2020). <i>Segmentation de texte non-supervisée pour la détection de thématiques à l'aide de plongements lexicaux</i>. In TALN 2020. <a href="https://hal.archives-ouvertes.fr/hal-02786181/file/proceedings.pdf#page=17" target="_blank">PDF</a></li>
            <li>Bourdois, L. (2020).  <i>L'augmentation de données en NLP</i>. from Chaudhary, A., A Visual Survey of Data Augmentation in NLP. <a href="https://lbourdois.github.io/blog/nlp/Data-augmentation-in-NLP/" target="_blank">Blog</a></li>
            <li>Pelloin, V., and Prouteau, T. (2020). <i>Apprentissage de plongements de mots sur des corpus en langue de spécialité: une étude d’impact</i>. In TALN 2020. <a href="https://hal.archives-ouvertes.fr/hal-02786181/document#page=180" target="_blank">PDF</a></li>
            <li>Coulombe, C. (2020). <i>Techniques d’amplification des données textuelles pour l’apprentissage profond</i>. PhD Thesis TÉLUQ. <a href="https://r-libre.teluq.ca/1894/1/Thèse_Coulombe.pdf" target="_blank">PDF</a></li>
            <li>Billami, M. (2020). <i>DEESSE: A Generic Search Engine based on Artificial Intelligence</i>. Recherche Berger-Levrault. <a href="https://www.research-bl.com/2020/12/15/deesse-a-generic-search-engine-based-on-artificial-intelligence/" target="_blank">Blog</a></li>
            <li>Gilly, A. (2019). <i>The Semantic Architecture of Social Unrest</i>. <a href="https://www.arthurgilly.com/work/yellowjackets" target="_blank">Blog</a></li>
            <li>Hemamou, L., Felhi, G., Vandenbussche, V., Martin, J. C., and Clavel, C. (2019). <i>Hirenet: A hierarchical attention model for the automatic analysis of asynchronous video job interviews</i>. In Proceedings of the AAAI Conference on Artificial Intelligence. <a href="https://www.aaai.org/ojs/index.php/AAAI/article/view/3832" target="_blank">PDF</a></li>
            <li>Le Ngoc, L., and Haralambous, Y. (2019). <i>CCG Supertagging Using Morphological and Dependency Syntax Information</i>. In Computational Linguistics and Intelligent Text Processing.  <a href="https://hal.archives-ouvertes.fr/hal-02110790/document" target="_blank">PDF</a> </li>
            <li>Chow, J. (2019). <i>Lost in translation: fidelity-focused machine translation evaluation.</i> Master Thesis, Imperial College London. <a href="https://pdfs.semanticscholar.org/bba2/e6bbf135eb5572974df176b76f692881c81c.pdf" target="_blank">PDF</a></li>
            <li>Vincent, R. (2019). <i>Multilingual Poetry Generation</i>. Master Thesis Norwegian University of Science and Technology. <a href="https://ntnuopen.ntnu.no/ntnu-xmlui/bitstream/handle/11250/2634459/no.ntnu%3Ainspera%3A36079153%3A38772770.pdf" target="_blank">PDF</a></li>
            <li>Poelman, S. (2019). <i>Faking news recommendation: an exploration of content representation.</i>. Master Thesis UCL. <a href="https://dial.uclouvain.be/memoire/ucl/en/object/thesis%3A22117" target="_blank">PDF</a></li>
            <li>Bladier, T., Waszczuk, J., Kallmeyer, L., and Janke, J. H. (2019). <i>From partial neural graph-based LTAG parsing towards full parsing</i>. Computational Linguistics in the Netherlands Journal. <a href="https://clinjournal.org/clinj/article/view/90" target="_blank">PDF</a></li>
            <li>Dufter, P., and Schütze, H. (2019). <i>Analytical Methods for Interpretable Ultradense Word Embeddings.</i>. In Proceedings of EMNLP 2019. <a href="https://www.aclweb.org/anthology/D19-1111.pdf" target="_blank">PDF</a></li>
		    <li>Bardet, A., Loubère, L., Dugué, N., Hu, S. and Delpech, Y. (2019). <i>Proposer des analyses sémantiques ou discursives des contributions du GDN</i>. In <a href="https://github.com/nicolasdugue/hackatal2019" target="_blank">Hackatal 2019</a></li>
		    <li><a href="https://lettria.com" target="_blank">Lettria</a> (2019) &mdash; <i>Word embedding</i>. <a href="https://lettria.com/blog/word-embedding" target="_blank">Blog</a></li>
		    <li>De Caigny, K. Coussement, K.W. De Bock, S. Lessmann (2019). <i>Incorporating Textual Information in Customer Churn Prediction Models Based on a Convolutional Neural Network</i>. In International Journal of Forecasting</li>
                    <li>Hemamou, L., Felhi, G., Vandenbussche, V., Martin, J.-C. and Clavel, C. (2019). <i>HireNet: a Hierarchical Attention Model for the Automatic Analysis of Asynchronous Video Job Interviews</i>. In AAAI 2019. <a href="https://www.aaai.org/Papers/AAAI/2019/AAAI-HemamouL.5951.pdf" target="_blank">PDF</a></li>
		    <li>Hmida, F., Billami, M. B., François, T. and Gala, N. (2018). <i>Assisted Lexical Simplification for French Native Children with Reading Difficulties</i>. In Proceedings of the Workshop Automatic Text Adaptation, 11th International Conference on Natural Language Generation (INLG 2018), Tilburg. <a href="https://www.ida.liu.se/~evere22/ATA-18/papers/paper_5.pdf" target="_blank">PDF</a></li>
		    <li>Moot, R. (2017). <i>Combining logical and distributional methods in type-logical grammars</i>. Journal of Language Modelling. <a href="https://hal-lirmm.ccsd.cnrs.fr/lirmm-01651508/" target="_blank">HAL</a></li>
            <li>Dusserre, E., and Padró, M. (2017). <i>Bigger does not mean better! We prefer specificity</i>. In IWCS 2017. Montpellier. <a href="http://www.aclweb.org/anthology/W17-6908" target="_blank">PDF</a></li>
            <li>Linz, N., Tröger, J., Alexandersson, J., and König, A. (2017). <i>Using Neural Word Embeddings in the Analysis of the Clinical Semantic Verbal Fluency Task</i>. In IWCS 2017. Montpellier</li>
		    <li> Lefebvre-Brossard, A., Spaeth, A., and Desmarais, M. C. (2017). <i>Encoding User as More Than the Sum of Their Parts: Recurrent Neural Networks and Word Embedding for People-to-people Recommendation</i>. In Proceedings of the 25th Conference on User Modeling, Adaptation and Personalization <a href="http://dl.acm.org/citation.cfm?id=3079700" target="_blank">ACM</a></li>
            <li>Wang, R. (2017). <i>Second Attempt at Building a Language Translator</i>. <a href="https://runze.github.io/2017/09/07/second-attempt-at-building-a-language-translator/" target="_blank">Blog</a></li>
            <li>Sehikh, I., Fohr, D., & Illina, I. (2017). <i>Topic Segmentation in ASR Transcripts using Bidirectional RNNS for Change Detection</i>. In 2017 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU). <a href="https://hal.archives-ouvertes.fr/hal-01599682/document" target="_blank">PDF</a></li>
            <li>Ebert, S. (2017). <i>Artificial Neural Network Methods Applied to Sentiment Analysis</i>. PhD Thesis Ludwig-Maximilians-Universität München. <a href="https://d-nb.info/1132510953/34" target="_blank">PDF</a></li>
		    <li><i>Practical Deep Learning For Coders</i> (2017) &mdash; Lesson <a href="http://forums.fast.ai/t/lesson-13-wiki/2332" target="_blank">13</a> &mdash; <a href="http://www.fast.ai" target="_blank">Fast.ai</a> project</li>
            <li>Povolny, F., Matejka, P., Hradis, M., Popková, A., Otrusina, L., Smrz, P. (2016). <i>Multimodal Emotion Recognition for AVEC 2016 Challenge</i>. In Proceedings of the 6th International Workshop on Audio/Visual Emotion Challenge</li>
            <li>EU Project <i>MixedEmotions</i> (2016) &mdash; <i>Social Semantic Emotion Analysis for Innovative Multilingual Big Data Analytics Markets</i></li>
            <li>Rothe, S., Ebert, S. and Schütze, H. (2016). <i>Ultradense Word Embeddings by Orthogonal Transformation</i>. NAACL 2016. San Diego</li>
            <li>Fauconnier, J. P., Kamel, M. (2015). <i>Discovering Hypernymy Relations using Text Layout</i>. *SEM 2015. Denver. <a href="https://embeddings.net/papers/Fauconnier_Kamel_SEM2015.pdf">PDF</a></li>
                </ul>
                </br>
                <h4>Annotated copora</h4>
                <p>Annotated corpora built during my PhD Thesis:</p>
                <ul>
                    <li><a href="https://github.com/fauconnier/corpus-LARA" target="_blank">corpus-LARA</a>: The corpus LARA is a French corpus of Wikipedia pages annotated with enumerative structures. </li>
                    <li><a href="https://github.com/fauconnier/corpus-LING_GEOP" target="_blank">corpus-LING_GEOP</a>: LING_GEOP is a corpus with visual and logical clues. The PDF documents come from <a href="http://redac.univ-tlse2.fr/corpus/annodis/me_download/index_en.html" target="_blank">ANNODIS-ME</a>.</li>
                </ul>


                <!-- Experience -->
                <h3>Experience<span id="experience" class="anchor"/></h3>

                <h4>Laboratory life</h4>
                <ul>
                    <li>Member of the <a href="http://www.irit.fr" target="_blank">IRIT</a> doctoral committee</li>
                    <li>Member of the <a href="http://jetou2015.free.fr/index-en.htm" target="_blank">JéTou 2015</a> organization committee </li>
                </ul>
                <h4>Review</h4>
                <ul>
                    <li>Subreviewer for <a href="http://iswc2016.semanticweb.org/" target="_blank">ISWC 2016</a> (<a href="http://rd.springer.com/book/10.1007/978-3-319-46523-4" target="_blank">Springer</a>)</li>

                    <li>Subreviewer for <a href="http://iswc2014.semanticweb.org/" target="_blank">ISWC 2014</a> (<a href="http://link.springer.com/book/10.1007%2F978-3-319-11964-9" target="_blank">Springer</a>)</li>
                    <li>Subreviewer for <a href="http://www.k-cap.org/kcap13/events.kmi.open.ac.uk/kcap2013/" target="_blank">K-CAP 2013</a> (<a href="http://dl.acm.org/citation.cfm?id=2479832" target="_blank">ACM</a>) </li>
                </ul>
                <h4>Jobs &amp; internships</h4>
                <ul>
                    <li>Axe TAL, <a href="http://w3.erss.univ-tlse2.fr/textes/operations/operation4-EN.html" target="_blank">CLEE-ERSS</a>, Université Toulouse II, 2012. Evaluation of the French  <a href="http://github.com/urieli/Talismane" target="_blank">Talismane</a> parser.</li>
                    <li>Division ICT, <a href="http://www.fagg-afmps.be/en/" target="_blank">Federal Agency for Medicines and Health Products</a>, Belgium, 2011. Treatment of <a href="https://eudract.ema.europa.eu/" target="_blank">EudraCT</a> data.</li>
                    <li>Software &amp; Technologies, <a href="https://www.cetic.be/spip.php?lang=en" target="_blank">CETIC</a>, Belgium, 2010. Development of the semantic search engine <a href="http://www.slideshare.net/MusicNet/jp-fauconnier-j-roumier-musonto-a-semantic-search-engine-dedicated-to-music-and-musicians#stats-panel" target="_blank">MusOnto</a>.</li>
                    <li>Division PRE, <a href="http://www.fagg-afmps.be/en/" target="_blank">Federal Agency for Medicines and Health Products</a>, Belgium, 2009. Database integrity verification.</li>
                </ul>

                <!-- Links -->
                <h3>Links<span id="links" class="anchor"/></h3>
                <ul>
                    <li><a href="https://github.com/fauconnier/" class="user-mention" target="_blank">Github profile</a></li>
                    <li><a href="http://www.quora.com/Jean-Philippe-Fauconnier/answers" target="_blank">Quora profile</a></li>
                    <li><a href="https://www.linkedin.com/in/jean-philippe-fauconnier-00b585172/" target="_blank">LinkedIn profile</a></li>
                </ul>
            </section>

            <!-- Footer -->
            <footer>
                <p><small>Hosted on <a href="http://github.com/fauconnier" target="_blank">GitHub</a> Pages &mdash; Original layout by <a href="https://github.com/orderedlist/minimal" target="_blank">orderedlist</a> &mdash; Slightly modified with <a href="http://www.vim.org/about.php" target="_blank">Vim</a></small></p>
                <!-- Vim, What Else? -->
            </footer>

        </div>
    </body>
</html>
